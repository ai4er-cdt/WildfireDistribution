{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "621eff73-97c1-4fe5-9afb-cb5bcdcb25c3",
   "metadata": {},
   "source": [
    "# Here we manually create ResNet 34 for application to ImageNet - 1k classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41aa48e8-8d56-4041-ab4d-440265414ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e2851-ff81-48ef-abff-742dc4f3beb8",
   "metadata": {},
   "source": [
    "# Explore Input Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb6fa32-8020-4fa5-824a-e3e073086863",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn([2,3,224,224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e711dfe0-8333-498f-9d9f-435d6c14fec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape # bs,rgb channels , width,height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280cde5e-cbae-474b-9a6c-09c54d3a098b",
   "metadata": {},
   "source": [
    "Pytorch nn.Conv2d layer expects inputs of (batch_size, channels, height, width).\n",
    "\n",
    "We are considering batch size of 2, 3 RGB color channels, height and width of 224 each. It is a rank 4 tensor\n",
    "\n",
    "## Question - what is batch size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938e076-d274-444b-9500-8537e4c0cf4f",
   "metadata": {},
   "source": [
    "# Convolution block\n",
    "First we are going to construct a small sequential network for initial convolution block of ResNet. It's the very first layer in our resnet architecture.\n",
    "\n",
    "It consists of 4 operations,\n",
    "\n",
    "- Convolution\n",
    "- Batch Normalization\n",
    "- ReLU activation function\n",
    "- Maxpooling\n",
    "\n",
    "Conv2d here: 3 input channels, 64 Kernels creating 64 feature maps, 7 * 7 kernel size. \n",
    "how to get padding 3? Maybe from the desired output size ? we get output of half the size due to stride and padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fdd9d3f-4fca-434d-9ff4-2103940e593c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_block = nn.Sequential(nn.Conv2d(3,64,kernel_size=7, stride=2, padding=3, bias=False), #112,112\n",
    "                       nn.BatchNorm2d(64),\n",
    "                       nn.ReLU(inplace=True),\n",
    "                       nn.MaxPool2d(kernel_size=3, stride=2, padding=1)) # 56,56\n",
    "conv_block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fb091-21a4-4754-bdf3-06ffea001ea9",
   "metadata": {},
   "source": [
    "Conv2d layer takes 3 input channels and generate 64 filters/channels (kernels) i.e feature maps. We can choose how many features we want to generate by convolution operation.\n",
    "\n",
    "Here, kernel size is 7 X 7 , stride is 2 and padding 3. Padding adds border of zeros around your input matrix.\n",
    "\n",
    "Conv2d layer downsamples input when stride is equal to 2, i.e convolution window skips over 1 pixel.\n",
    "\n",
    "So after conv2d layer output shape will be (2,64,112,112) tensor of activations. Basically height and width of input grid reduces to half.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef89fa1-9834-43d4-8d3f-3b9475441eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 112, 112])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inp=nn.Conv2d(3,64,kernel_size=7, stride=2, padding=3, bias=False)(inp)\n",
    "#inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26284cc-d63a-4471-b4ef-de87f574fe11",
   "metadata": {},
   "source": [
    "After maxpooling operation with stride of 2 again output from conv2d->batchNorm->Relu gets downsampled to half.\n",
    "\n",
    "Let's check what is shape of output after conv_block operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef5422e-d01e-4126-a531-09987d1bdeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 56, 56])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out=conv_block(inp)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11a4a24-dab0-4c0c-8540-6c5447722b7b",
   "metadata": {},
   "source": [
    "# Residual block\n",
    "After 2 convolution operations, the input of those 2 convolution is added to their output. This is the core of the Residual method: the extra input x does not add parameters or complexity to model. \n",
    "\n",
    "# Basic Block\n",
    "Each basic block constitutes of 2 convolution operations.\n",
    "\n",
    "Each convolutional layer is followed by a batch normalization layer and a ReLU activation function. After the 2nd Conv, input is added to that output before applying ReLU. Downsampling may have to be applied \n",
    "\n",
    "FOr the 3 x 3 Kernel, the padding of 1 and stride 1 means output is the same size as the input for the first conv layer \n",
    "## Question - how to get the expansion value from the paper? Why is Bias False? what does the downsampling do - I know that later we may update downsampling, but why does that replace the original identity? \n",
    "when the stride is not 1, ie the first layer when stride =2, in order to add the original input x to the output of the second conv, we must downsample the x so that they are same dimensions - Ws in the orign paper. This downsample is 1 x 1 convolution + Batch Norm  \n",
    "\n",
    "\n",
    "### Question: how does the number of filters, the number or channels and the input shapes interact? To calc output dimensions we use \n",
    "$\\frac{h - k + 2p}{s} + 1$ where h = dimension, k = kernel size, p = padding, s= stride\n",
    "\n",
    "Why does input and output number of channels change on the first conv layer but not the second? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0293accd-e550-4204-823e-54982aa0c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                     padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2671c067-e459-4224-913a-d390fb22d5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicBlock(64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc207a67-4023-452d-8ea4-0171f853f90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 56, 56])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn((2,64,56,56))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd4b1a99-f5b8-44d2-a73d-7aacbee137da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 56, 56])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = BasicBlock(64,64)\n",
    "block(t).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b22509-c261-4822-ab34-735a8ce17653",
   "metadata": {},
   "source": [
    "# make_layer()\n",
    "Next 4 layers after initial conv_block are called as layer 1, 2, 3, 4 respectively. Each layer consists of multiple convolution blocks. Conv_block refers to set of operations as in Convolution->BatchNorm->ReLU activation to an input. Instead of adding new layers to create a deeper neural network, resnet authors added many conv_block within each layer, thus keeping depth of neural network same - 4 layers.\n",
    "### Question: why does coding them up in 'blocks' mean that they dont count as a whole new layer? Is it not just notation? \n",
    "\n",
    "In the PyTorch implementation they distinguish between the blocks that includes 2 operations – Basic Block – and the blocks that include 3 operations – Bottleneck Block.\n",
    "\n",
    "The make_layer() function takes which type of block to use as an argument, the number of input and output filters, and number of blocks to be stacked together. Every layer downsamples the input at the start using stride equals to 2 i.e for 1st convolutional layer in 1st block of a layer. For all the rest convolution layers stride is 1. Also, if downsample has to be applied to input, stride 2 convolution is used followed by BatchNorm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8cd0b79-152a-4806-85d0-3d7d3fe80fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_layer(block, inplanes,planes, blocks, stride=1):\n",
    "    downsample = None  \n",
    "    if stride != 1 or inplanes != planes:\n",
    "        downsample = nn.Sequential(            \n",
    "            nn.Conv2d(inplanes, planes, 1, stride, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "    layers = []\n",
    "    layers.append(block(inplanes, planes, stride, downsample))\n",
    "    inplanes = planes\n",
    "    for _ in range(1, blocks):\n",
    "        layers.append(block(inplanes, planes))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "254813c5-7f50-49f5-9bce-d2e0b1bc4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=[3, 4, 6, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b31fa96-114d-4243-aee7-76c5c19bb908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): BasicBlock(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 =_make_layer(BasicBlock, inplanes=64,planes=64, blocks=layers[0])\n",
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "373426f9-1e41-4376-bd65-4a99240b8069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (2): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (3): BasicBlock(\n",
       "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 = _make_layer(BasicBlock, 64, 128, layers[1], stride=2)\n",
    "layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee0d58-af15-4409-83e3-cfc48a9694f4",
   "metadata": {},
   "source": [
    "# Why we need to downsample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52b11f7a-d602-4ed8-9b3e-acb78486bf70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 56, 56])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((2,64,56,56))\n",
    "t.shape #batch, RGB channels/filters,width,height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db143143-c66e-4d06-9e1f-f0693113b597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = nn.Conv2d(64,128,kernel_size = 3, stride = 2, padding = 1)(t)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1ca39c9-0e94-43d3-8f2b-d248561fad77",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (56) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mo\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mt\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (28) must match the size of tensor b (56) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "o+t  #height and width not matching  56,56 !=28,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a3c58fa-1d62-4e9f-a8df-dfd7afd02ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128, 28, 28]), torch.Size([2, 128, 28, 28]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we apply the 1 x 1 convolution to t to create something that we can add to o, the output of the conv layers \n",
    "t_d =nn.Conv2d(64,128,1,2,0)(t)\n",
    "o.shape,t_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "903a49ee-d043-40e7-81d7-905100fc7a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 28, 28])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(o+t_d).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5443d-83b2-4c83-ae19-2c6414ea29c2",
   "metadata": {},
   "source": [
    "# Classifier block\n",
    "This is a fully connected layer. It's the final layer in our resnet architecture. It consists of 3 operations -\n",
    "\n",
    "- Average pooling layer - aggregates all features. It's output grid size is 1X 1 which forms rank 3 tensor of (512, 1,1)\n",
    "\n",
    "- Flatten- Our loss function expects a vector of tensor instead of rank 3 tensor. So in forward() we call 'torch.flatten' to remove any unit axis from matrix and make it just a vector of length 512.\n",
    "        x = torch.flatten(x, 1)\n",
    "- Linear Layer - It's a fully connected layer just before applying softmax, which takes in 512 features and outputs 1000 class probabilities. (In case of Imagenet, we have 1000 categories.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "505c3917-44cb-42b3-8355-8ec6a4d14fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (1): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=1000\n",
    "nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
    "              nn.Linear(512 , num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306161cc-591e-424f-af07-2fd856885f25",
   "metadata": {},
   "source": [
    "# Resnet class\n",
    "\n",
    "TO DO \n",
    "turn first layer into callable module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e14019c-5959-40c4-9bf6-61c119501283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.inplanes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 , num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None  \n",
    "   \n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        \n",
    "        self.inplanes = planes\n",
    "        \n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)           # 224x224\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)         # 112x112\n",
    "\n",
    "        x = self.layer1(x)          # 56x56\n",
    "        x = self.layer2(x)          # 28x28\n",
    "        x = self.layer3(x)          # 14x14\n",
    "        x = self.layer4(x)          # 7x7\n",
    "\n",
    "        x = self.avgpool(x)         # 1x1\n",
    "        x = torch.flatten(x, 1)     # remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aad8595a-0159-45c4-b6fa-248c58e1ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34():\n",
    "    layers=[3, 4, 6, 3]\n",
    "    model = ResNet(BasicBlock, layers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe9e5630-bc46-481b-a831-5a87e5432706",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "546412f1-15e9-439f-acba-3472349d93bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606f608-336e-4dda-82c5-dfbda221681f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_torch",
   "language": "python",
   "name": "geo_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
