{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833b03ee",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to define and test the functions needed for the MODIS class for pre-processing the data. Having explored torchgeo, I have found that the preprocessing must be seperated from the torch work due to limitations on the RasterDataset class. Much of the preprocessing functionality can be taken from the Jupyter Notebooks already written.\n",
    "\n",
    "Base Class: MODIS dataset <br>\n",
    "Subclasses: Julian Day and Confidence Level \n",
    "\n",
    "Attributes required:<br>\n",
    "    - 'root': where we can find all of the MODIS files (in practice a CEDA location accessed via JASMIN) - DONE<br>\n",
    "    <br>\n",
    "Methods required: <br>\n",
    "    - extract data: look in root dir and form dataset object from files - DONE <br>\n",
    "    - crop data: using a shape file, crop the dataset spatially - DONE <br>\n",
    "    - plot data: create plots for the current dataset - TODO <br>\n",
    "    - save data: save the altered files back in their tif format so torchgeo is ready to use - TODO<br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac32010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "\n",
    "#import shp_utility_functions as suf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397b86e",
   "metadata": {},
   "source": [
    "### Temp: Copied in shape utility functions (reside in preprocessing folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297fd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vertices(shape_file_path):\n",
    "    \"\"\"Returns a numpy array of the lat/lons corresponding to the vertices of a polygon defined by a shape file.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    shape_file_path -- realtive path where the shp and shx files are located (both required)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the vertices using fiona\n",
    "    with fiona.open(shape_file_path) as shape_data:\n",
    "        vertices = shape_data[0]['geometry']['coordinates'][0]\n",
    "        \n",
    "    # Return them as a numpy array\n",
    "    return np.array(vertices)\n",
    "    \n",
    "\n",
    "def crop_data_spatially(input_data, shape_file_path, zero_remap):\n",
    "    \"\"\"Crops input data to keep only the elements within the spatial bounds defined by the input shape file.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    input_data -- DataArray of input data and corresponding x/y (latitude/longitude) coordinates\n",
    "    shape_file_path -- realtive path where the shp and shx files are located (both required)\n",
    "    zero_remap -- the new value that elements outside the spatial bounds (but not dropped from the output DataArray)\n",
    "                  are mapped to after the crop has occurred\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check that zero_remap is the same type as the values in input_data\n",
    "    first_element = input_data.item(tuple(np.zeros(len(input_data.shape), int)))\n",
    "    try:\n",
    "        if not ((isinstance(zero_remap, (int, np.integer)) and isinstance(first_element, (int, np.integer))) or\n",
    "                 (isinstance(zero_remap, (float, np.float64)) and isinstance(first_element, (float, np.float64)))):\n",
    "            raise TypeError('The zero_remap value provided must match the type of the input data:', type(zero_remap), type(input_data.values.dtype)) \n",
    "    \n",
    "    except TypeError as error:\n",
    "        print(error.args)\n",
    "    \n",
    "    \n",
    "    # Extract the vertice's latitude/longitudes from the shape file\n",
    "    vertices = extract_vertices(shape_file_path) \n",
    "    \n",
    "    # Define a geometry object to define the polygon\n",
    "    shape_geometry = [{'type': 'Polygon',\n",
    "                       'coordinates': [vertices]}]\n",
    "    \n",
    "    # Crop the data using the latitude/longitudes and remap the new zero values \n",
    "    data_cropped = (input_data-zero_remap).rio.clip(shape_geometry, \"epsg:4326\") + zero_remap\n",
    "    return data_cropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a71a3",
   "metadata": {},
   "source": [
    "## Base Class Specification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34e58fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PP_ModisFireCCI():\n",
    "    \"\"\"Abstract base class for the preprocessing of all MODIS Fire CCI Burned Area datasets. This class should\n",
    "       not be called directly - instead use the subclass objects.\n",
    "\n",
    "    `MODIS Fire_cci Burned Area Dataset: <https://geogra.uah.es/fire_cci/firecci51.php>`_\n",
    "    This dataset was developed by ESA, utilising the MODIS satellite. The dataset contains\n",
    "    information at both PIXEL (~250m) and GRID (0.25 degrees) resolutions. A variety of \n",
    "    useful information is contained within the datasets including Julian Day of burn, \n",
    "    confidence level of burn etc.\n",
    "    For more information, see:\n",
    "    * `User Guide\n",
    "      <https://climate.esa.int/media/documents/Fire_cci_D4.2_PUG-MODIS_v1.0.pdf>`_\n",
    "    \"\"\"\n",
    "    \n",
    "    #: Root directory (in CEDA) where the MODIS files can be found.\n",
    "    root = None\n",
    "    \n",
    "    #: Glob expression used to search for files.\n",
    "    filename_glob = None\n",
    "    \n",
    "    #: Regular expression used to extract date from filename.\n",
    "    filename_regex = \"(?P<date>\\d{6})\\S{33}(?P<tile_number>\\d).*\"\n",
    "\n",
    "    #: Date format string used to parse date from filename.\n",
    "    date_format = \"%Y%m\"\n",
    "    \n",
    "    #: DataArray used to store the relevant MODIS data.\n",
    "    data = None\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a new Preprocessing instance.\n",
    "        Args:\n",
    "            root: root directory where dataset can be found\n",
    "        Raises:\n",
    "            FileNotFoundError: if no files are found in ``root``\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set the root attribute to that passed into the constructor\n",
    "        self.root = root\n",
    "      \n",
    "    \n",
    "    def populate(self):\n",
    "        \"\"\"Extract the relevant data from the root directory and store it within the object using a DataArray\"\"\"\n",
    "        \n",
    "        # Populate a list of DataArrays using the seperate files\n",
    "        dataArrays = []\n",
    "        pathname = os.path.join(self.root, \"**\", self.filename_glob)\n",
    "        filename_regex = re.compile(self.filename_regex, re.VERBOSE)\n",
    "        \n",
    "        # For each file found, index the data using the date it corresponds to\n",
    "        for filepath in glob.iglob(pathname, recursive=True):\n",
    "            match = re.match(self.filename_regex, os.path.basename(filepath))\n",
    "            data = rxr.open_rasterio(filepath)\n",
    "            data = data.assign_coords(date=match.group(\"date\"))\n",
    "            dataArrays.append(data)\n",
    "            \n",
    "        # Finally concatenate the DataArrays and store the result in the object     \n",
    "        self.data = xr.concat(dataArrays, dim='date')\n",
    "        \n",
    "        \n",
    "    def crop(self, shape_root, zero_remap):\n",
    "        \"\"\"Crop the whole dataset spatially according to some shape files.\n",
    "        \n",
    "        Args:\n",
    "            shape_root: shape file (.shp) path\n",
    "            zero_remap: the new value that elements outside the spatial bounds (but not dropped from the output \n",
    "                        DataArray) are mapped to after the crop has occurred\n",
    "        \"\"\"\n",
    "        \n",
    "        # Call the relevant utility function \n",
    "        self.data = crop_data_spatially(self.data, shape_root, zero_remap)\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c817e0",
   "metadata": {},
   "source": [
    "## Julian Day Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d77f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PP_ModisJD(PP_ModisFireCCI):\n",
    "    \"\"\"\n",
    "    Preprocessing class for the burn day (in Julian Days) that a burned area is first seen on.\n",
    "    \n",
    "    Possible values (mask not image): \n",
    "        -2 = pixel not of burnable type e.g. water, urban areas or permanent snow/ice.\n",
    "        -1 = pixel not observed in the month (possible cloud cover etc)\n",
    "         0  = pixel is not burned \n",
    "        [1,366] = Julian Day of first detection when the pixel is burned \n",
    "    \"\"\"\n",
    "\n",
    "    filename_glob = \"*JD.tif\" \n",
    "    \n",
    "    \n",
    "    def plot(self, date_list):\n",
    "    \"\"\"Plots the data corresponding to each of the dates listed in date_list.\n",
    "    \n",
    "    Args: \n",
    "        date_list: list of dates in the format YYYYMM that are requested for plotting\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # FOR TESTING ONLY\n",
    "    month_of_interest = \"202004\"\n",
    "    \n",
    "    # N is the number of colours choose from spectrum (=number of days in the month being considered)\n",
    "    \n",
    "    # COULD PUT IN UTILITY FUNCTION\n",
    "    start_JD = datetime.strptime(month_of_interest, self.date_format).timetuple().tm_yday\n",
    "    end_JD = start_JD + monthrange(int(month_of_interest[:4]), int(month_of_interest[4:]))[1] - 1\n",
    "    N = end_JD-start_JD\n",
    "\n",
    "    # Force the first colours in the map to be: -2 = dark grey, -1 = light grey, 0 = white and 0-start_JD = black \n",
    "    # (to signify axis break if not January). Then have a scale of yellow -> orange -> red for the Julian Day of burn days \n",
    "    cmaplist1 = plt.cm.gray(np.linspace(0, 1, 4))[1:]\n",
    "    cmaplist2 = plt.cm.YlOrRd(np.linspace(0, 1, N))\n",
    "\n",
    "    if start_JD == 1:\n",
    "        # Create the new colour map for January case\n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', np.vstack((cmaplist1, cmaplist2)), N+2)\n",
    "\n",
    "        # Define the discrete bin bounds\n",
    "        bounds = np.linspace(-2.5, end_JD+0.5, N+3)\n",
    "\n",
    "    else:\n",
    "        # Add black square for line break for non-January month\n",
    "        cmaplist1 = np.vstack((cmaplist1, np.array([0,0,0,1])))\n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', np.vstack((cmaplist1, cmaplist2)), N+3)\n",
    "        bounds = np.concatenate([np.linspace(-2.5, 0.5, 4), np.linspace(start_JD-0.5, end_JD+0.5, N)])\n",
    "\n",
    "    # Define the ticks for the colour bar\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "    ticks = np.concatenate([np.array([-2,-1,0]),np.arange(start_JD,end_JD+1)])\n",
    "\n",
    "    # Plot the data\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "    fig, ax = plt.subplots(2, figsize=(13,20))\n",
    "    burn_days_clipped.plot(ax=ax[0], cmap=cmap, norm=norm, cbar_kwargs={'ticks': ticks,'label': 'Julian Day (1-365/366)'});\n",
    "\n",
    "    # Finally, add a blue square to illustrate the training area\n",
    "    training_coords = extract_vertices(\"Shape Files/Project_area.shp\")\n",
    "    ax[0].plot(training_coords[:,0],training_coords[:,1],'--b',linewidth=1);\n",
    "    ax[0].set_title('March 2020',fontsize=20,fontweight=\"bold\");\n",
    "    ax[0].set_xlabel('Longitude (\\N{DEGREE SIGN}W)',fontsize=16);\n",
    "    ax[0].set_ylabel('Latitude (\\N{DEGREE SIGN}N)',fontsize=16);\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbd57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj = PP_ModisJD(\"Modis Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391dcb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ce806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj.crop(\"Shape Files/whole_map.shp\", -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78209a",
   "metadata": {},
   "source": [
    "## Confidence Level Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca38eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc4539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
