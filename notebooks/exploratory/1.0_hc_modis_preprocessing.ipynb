{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833b03ee",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to define and test the functions needed for the MODIS class for pre-processing the data. Having explored torchgeo, I have found that the preprocessing must be seperated from the torch work due to limitations on the RasterDataset class. Much of the preprocessing functionality can be taken from the Jupyter Notebooks already written.\n",
    "\n",
    "Base Class: MODIS dataset <br>\n",
    "Subclasses: Julian Day and Confidence Level \n",
    "\n",
    "Attributes required:<br>\n",
    "    - 'root': where we can find all of the MODIS files (in practice a CEDA location accessed via JASMIN) - DONE<br>\n",
    "    <br>\n",
    "Methods required: <br>\n",
    "    - extract data: look in root dir and form dataset object from files - DONE <br>\n",
    "    - crop data: using a shape file, crop the dataset spatially - DONE <br>\n",
    "    - plot data: create plots for the current dataset - DONE <br>\n",
    "    - export data: save the altered files back in their tif format so torchgeo is ready to use - DONE<br>\n",
    "    - binarize data: change all data to zeros/ones only - DONE <br>\n",
    "    - non_zero: returns the proportion of non-zero elements in each dataArray - TODO <br>\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c34323",
   "metadata": {},
   "source": [
    "Example of how simple preprocessing/graphing will become by using this framework: <br>\n",
    "```python\n",
    "# Complete necessary preprocessing operations\n",
    "modis_data = PP_ModisJD(\"root dir\")\n",
    "modis_data.populate()\n",
    "modis_data.crop(\"shape dir/whole_map.shp\", -2)\n",
    "modis_data.binarize()\n",
    "\n",
    "# Plot new datasets for insights\n",
    "modis_data.plot([\"202003\",\"202004\",\"202005\"], \"shape dir/Project_area.shp\")\n",
    "\n",
    "# Preprocessing complete - save tif files to output directory for torchgeo to access independently of raw data\n",
    "modis_data.export(\"target dir\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac32010d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from calendar import monthrange\n",
    "\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import fiona\n",
    "\n",
    "#import shp_utility_functions as suf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397b86e",
   "metadata": {},
   "source": [
    "### Temp: Copied in shape utility functions (reside in preprocessing folder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297fd9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vertices(shape_file_path):\n",
    "    \"\"\"Returns a numpy array of the lat/lons corresponding to the vertices of a polygon defined by a shape file.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    shape_file_path -- realtive path where the shp and shx files are located (both required)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the vertices using fiona\n",
    "    with fiona.open(shape_file_path) as shape_data:\n",
    "        vertices = shape_data[0]['geometry']['coordinates'][0]\n",
    "        \n",
    "    # Return them as a numpy array\n",
    "    return np.array(vertices)\n",
    "    \n",
    "\n",
    "def crop_data_spatially(input_data, shape_file_path, zero_remap):\n",
    "    \"\"\"Crops input data to keep only the elements within the spatial bounds defined by the input shape file.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    input_data -- DataArray of input data and corresponding x/y (latitude/longitude) coordinates\n",
    "    shape_file_path -- realtive path where the shp and shx files are located (both required)\n",
    "    zero_remap -- the new value that elements outside the spatial bounds (but not dropped from the output DataArray)\n",
    "                  are mapped to after the crop has occurred\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check that zero_remap is the same type as the values in input_data\n",
    "    first_element = input_data.item(tuple(np.zeros(len(input_data.shape), int)))\n",
    "    try:\n",
    "        if not ((isinstance(zero_remap, (int, np.integer)) and isinstance(first_element, (int, np.integer))) or\n",
    "                 (isinstance(zero_remap, (float, np.float64)) and isinstance(first_element, (float, np.float64)))):\n",
    "            raise TypeError('The zero_remap value provided must match the type of the input data:', type(zero_remap), type(input_data.values.dtype)) \n",
    "    \n",
    "    except TypeError as error:\n",
    "        print(error.args)\n",
    "    \n",
    "    \n",
    "    # Extract the vertice's latitude/longitudes from the shape file\n",
    "    vertices = extract_vertices(shape_file_path) \n",
    "    \n",
    "    # Define a geometry object to define the polygon\n",
    "    shape_geometry = [{'type': 'Polygon',\n",
    "                       'coordinates': [vertices]}]\n",
    "    \n",
    "    # Crop the data using the latitude/longitudes and remap the new zero values \n",
    "    data_cropped = (input_data-zero_remap).rio.clip(shape_geometry, \"epsg:4326\") + zero_remap\n",
    "    return data_cropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a71a3",
   "metadata": {},
   "source": [
    "## Base Class Specification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e58fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PP_ModisFireCCI():\n",
    "    \"\"\"Abstract base class for the preprocessing of all MODIS Fire CCI Burned Area datasets. This class should\n",
    "       not be called directly - instead use the subclass objects.\n",
    "\n",
    "    `MODIS Fire_cci Burned Area Dataset: <https://geogra.uah.es/fire_cci/firecci51.php>`_\n",
    "    This dataset was developed by ESA, utilising the MODIS satellite. The dataset contains\n",
    "    information at both PIXEL (~250m) and GRID (0.25 degrees) resolutions. A variety of \n",
    "    useful information is contained within the datasets including Julian Day of burn, \n",
    "    confidence level of burn etc.\n",
    "    For more information, see:\n",
    "    * `User Guide\n",
    "      <https://climate.esa.int/media/documents/Fire_cci_D4.2_PUG-MODIS_v1.0.pdf>`_\n",
    "    \"\"\"\n",
    "    \n",
    "    #: Root directory (in CEDA) where the MODIS files can be found.\n",
    "    root = None\n",
    "    \n",
    "    #: Glob expression used to search for files.\n",
    "    filename_glob = None\n",
    "    \n",
    "    #: Regular expression used to extract date from filename.\n",
    "    filename_regex = \"(?P<date>\\d{6})\\S{33}(?P<tile_number>\\d).*\"\n",
    "\n",
    "    #: Date format string used to parse date from filename.\n",
    "    date_format = \"%Y%m\"\n",
    "    \n",
    "    #: DataArray used to store the relevant MODIS data.\n",
    "    data = None\n",
    "    \n",
    "    #: Binary flag signifying that data has been mapped to 0/1\n",
    "    binary_flag = False\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize a new Preprocessing instance.\n",
    "        Args:\n",
    "            root: root directory where dataset can be found\n",
    "        Raises:\n",
    "            FileNotFoundError: if no files are found in ``root``\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set the root attribute to that passed into the constructor\n",
    "        self.root = root\n",
    "      \n",
    "    \n",
    "    def populate(self):\n",
    "        \"\"\"Extract the relevant data from the root directory and store it within the object using a DataArray\"\"\"\n",
    "        \n",
    "        # Populate a list of DataArrays using the seperate files\n",
    "        dataArrays = []\n",
    "        pathname = os.path.join(self.root, \"**\", self.filename_glob)\n",
    "        filename_regex = re.compile(self.filename_regex, re.VERBOSE)\n",
    "        \n",
    "        # For each file found, index the data using the date it corresponds to\n",
    "        for filepath in glob.iglob(pathname, recursive=True):\n",
    "            match = re.match(self.filename_regex, os.path.basename(filepath))\n",
    "            data = rxr.open_rasterio(filepath)\n",
    "            data = data.assign_coords(date=match.group(\"date\"))\n",
    "            dataArrays.append(data)\n",
    "            \n",
    "        # Finally concatenate the DataArrays and store the result in the object     \n",
    "        self.data = xr.concat(dataArrays, dim='date')\n",
    "        \n",
    "        \n",
    "    def crop(self, shape_root, zero_remap=0):\n",
    "        \"\"\"Crop the whole dataset spatially according to some shape files.\n",
    "        \n",
    "        Args:\n",
    "            shape_root: shape file (.shp) path\n",
    "            zero_remap: the new value that elements outside the spatial bounds (but not dropped from the output \n",
    "                        DataArray) are mapped to after the crop has occurred\n",
    "                        \n",
    "        Raises:\n",
    "            ValueError: if object has not been populated with data before this function is called\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data is None:\n",
    "            raise ValueError(\"The data is = None. Try calling 'populate' to assign the object data before making this call.\") \n",
    "\n",
    "        # Call the relevant utility function \n",
    "        self.data = crop_data_spatially(self.data, shape_root, zero_remap)\n",
    "        \n",
    "        \n",
    "    def export(self, target_dir):\n",
    "        \"\"\"Saves the data contained within the object to some target directory (raster .tif files).\n",
    "        \n",
    "        Args:\n",
    "            target_dir: path of target directory for export\n",
    "                        \n",
    "        Raises:\n",
    "            ValueError: if object has not been populated with data before this function is called\n",
    "            CPLE_OpenFailedError: if target directory has not been created before calling this function\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data is None:\n",
    "            raise ValueError(\"The data is = None. Try calling 'populate' to assign the object data before making this call.\") \n",
    "\n",
    "            \n",
    "        # For each DataArray, save the data as a raster .tif file  \n",
    "        for dataArray in self.data:\n",
    "            output_name = \"PostProcessing_\" + str(dataArray.date.values)+ \"-\" + self.filename_glob[1:]\n",
    "            full_output_file = os.path.join(target_dir, output_name) \n",
    "            dataArray.rio.to_raster(full_output_file)\n",
    "            \n",
    "            \n",
    "    def \n",
    "                               \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c817e0",
   "metadata": {},
   "source": [
    "## Julian Day Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d77f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PP_ModisJD(PP_ModisFireCCI):\n",
    "    \"\"\"\n",
    "    Preprocessing class for the burn day (in Julian Days) that a burned area is first seen on.\n",
    "    \n",
    "    Possible values (mask not image): \n",
    "        -2 = pixel not of burnable type e.g. water, urban areas or permanent snow/ice.\n",
    "        -1 = pixel not observed in the month (possible cloud cover etc)\n",
    "         0  = pixel is not burned \n",
    "        [1,366] = Julian Day of first detection when the pixel is burned \n",
    "    \"\"\"\n",
    "\n",
    "    filename_glob = \"*JD.tif\" \n",
    "    \n",
    "    \n",
    "    def binarize(self):\n",
    "        \"\"\"Maps any data points which are greater than zero to 1.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: if object has not been populated with data before this function is called\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data is None:\n",
    "            raise ValueError(\"The data is = None. Try calling 'populate' to assign the object data before making this call.\") \n",
    "        \n",
    "        # If data is more than 0, replace it with 1, otherwise keep original value\n",
    "        self.data = xr.where(self.data > 0, 1, self.data)\n",
    "        \n",
    "        # Set the flag used for plotting functions\n",
    "        self.binary_flag = True\n",
    "    \n",
    "    \n",
    "    def plot(self, date_list, shape_root = None):\n",
    "        \"\"\"Plots the data corresponding to each of the dates listed in date_list.\n",
    "\n",
    "        Args: \n",
    "            date_list: list of dates in the format \"YYYYMM\" that are requested for plotting\n",
    "            shape_root: shape file (.shp) path of training area (optional)\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: if object has not been populated with data before this function is called\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data is None:\n",
    "            raise ValueError(\"The data is = None. Try calling 'populate' to assign the object data before making this call.\") \n",
    "        \n",
    "        \n",
    "        # Initialise the subplot object\n",
    "        plt.rcParams.update({'font.size': 13})\n",
    "        fig, ax = plt.subplots(len(date_list), figsize=(13,10*len(date_list)))\n",
    "        \n",
    "        \n",
    "        for idx, date in enumerate(date_list):\n",
    " \n",
    "            # Want first colours in the map to be: -2 = dark grey, -1 = light grey, 0 = white\n",
    "            cmaplist1 = plt.cm.gray(np.linspace(0, 1, 4))[1:]\n",
    "        \n",
    "            # case: non-binarized data\n",
    "            if not self.binary_flag:\n",
    "                \n",
    "                # Find the first and last Julian Day present in the month requested \n",
    "                start_JD = datetime.strptime(date, self.date_format).timetuple().tm_yday\n",
    "                end_JD = start_JD + monthrange(int(date[:4]), int(date[4:]))[1] -1\n",
    "                range_JD = end_JD - start_JD\n",
    "\n",
    "                # Then have a scale of yellow -> orange -> red for the Julian Day of burn days \n",
    "                cmaplist2 = plt.cm.YlOrRd(np.linspace(0, 1, range_JD))\n",
    "\n",
    "                # case: January\n",
    "                if start_JD == 1:\n",
    "                    cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', np.vstack((cmaplist1, cmaplist2)), range_JD+2)\n",
    "                    bounds = np.linspace(-2.5, end_JD+0.5, range_JD+3)\n",
    "\n",
    "                # case: February-December\n",
    "                else:\n",
    "                    # Want 0-start_JD = black, to signify axis break \n",
    "                    cmaplist1 = np.vstack((cmaplist1, np.array([0,0,0,1])))\n",
    "                    cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', np.vstack((cmaplist1, cmaplist2)), range_JD+3)\n",
    "                    bounds = np.concatenate([np.linspace(-2.5, 0.5, 4), np.linspace(start_JD-0.5, end_JD+0.5, range_JD)])\n",
    "\n",
    "                # Define the ticks for the colour bar\n",
    "                norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "                ticks = np.concatenate([np.array([-2,-1,0]),np.arange(start_JD,end_JD+1)])\n",
    "                                 \n",
    "                # Plot the data\n",
    "                self.data.sel(date=date).plot(ax=ax[idx], cmap=cmap, norm=norm, cbar_kwargs={'ticks': ticks,'label': 'Julian Day (1 -> 366)'});\n",
    "\n",
    "            # case: binarized data\n",
    "            else: \n",
    "                bounds = np.linspace(-2.5, 1.5, 5)\n",
    "                cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', np.vstack((cmaplist1, np.array([1,0,0,0]))), 4)\n",
    "                norm = mpl.colors.BoundaryNorm(bounds, cmap.N)\n",
    "                ticks = np.array([-2,-1,0,1])\n",
    "\n",
    "                self.data.sel(date=date).plot(ax=ax[idx], cmap=cmap, norm=norm, cbar_kwargs={'ticks': ticks,'label': 'Burn Classification'});\n",
    "\n",
    "                \n",
    "            # Add remaining components to the graph\n",
    "            ax[idx].set_title(date[4:] + '/' + date[:4], fontsize=20, fontweight=\"bold\");\n",
    "            ax[idx].set_xlabel('Longitude (\\N{DEGREE SIGN}W)',fontsize=16);\n",
    "            ax[idx].set_ylabel('Latitude (\\N{DEGREE SIGN}N)',fontsize=16);\n",
    "\n",
    "            # Optionally add a blue square to illustrate the training area\n",
    "            if shape_root != None:\n",
    "                training_coords = extract_vertices(shape_root)\n",
    "                ax[idx].plot(training_coords[:,0],training_coords[:,1],'--b',linewidth=1);\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbd57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj = PP_ModisJD(\"Modis Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391dcb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj.populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ce806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj.crop(\"Shape Files/whole_map.shp\", -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b193d539",
   "metadata": {},
   "outputs": [
    {
     "ename": "CPLE_OpenFailedError",
     "evalue": "Attempt to create new tiff file '/Users/hamishcampbell/Documents/Cambridge/Lent/GTC/WildfireDistribution/notebooks/exploratory/Test1/PostProcessing_202003-JD.tif' failed: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m2/p1rj5gjx7fjb0thvr_bpmyf40000gn/T/ipykernel_12036/3448520848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/hamishcampbell/Documents/Cambridge/Lent/GTC/WildfireDistribution/notebooks/exploratory/Test1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/m2/p1rj5gjx7fjb0thvr_bpmyf40000gn/T/ipykernel_12036/1435546082.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(self, target_dir)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0moutput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"PostProcessing_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename_glob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mfull_output_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdataArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Note: issue if folder to save in doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/modis/lib/python3.7/site-packages/rioxarray/raster_array.py\u001b[0m in \u001b[0;36mto_raster\u001b[0;34m(self, raster_path, driver, dtype, tags, windowed, recalc_transform, lock, compute, **profile_kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mcompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mout_profile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/modis/lib/python3.7/site-packages/rioxarray/raster_writer.py\u001b[0m in \u001b[0;36mto_raster\u001b[0;34m(self, xarray_dataarray, tags, windowed, lock, compute, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nodata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_nodata_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nodata\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraster_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0m_write_metatata_to_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxarray_dataarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_dask_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxarray_dataarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/modis/lib/python3.7/site-packages/rasterio/env.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0menv_ctor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/modis/lib/python3.7/site-packages/rasterio/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                               \u001b[0msharing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msharing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                                               **kwargs)\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             raise ValueError(\n",
      "\u001b[0;32mrasterio/_io.pyx\u001b[0m in \u001b[0;36mrasterio._io.DatasetWriterBase.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mrasterio/_err.pyx\u001b[0m in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: Attempt to create new tiff file '/Users/hamishcampbell/Documents/Cambridge/Lent/GTC/WildfireDistribution/notebooks/exploratory/Test1/PostProcessing_202003-JD.tif' failed: No such file or directory"
     ]
    }
   ],
   "source": [
    "test_obj.export(\"/Users/hamishcampbell/Documents/Cambridge/Lent/GTC/WildfireDistribution/notebooks/exploratory/Test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1073575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj.binarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [\"202003\",\"202004\",\"202005\"]\n",
    "test_obj.plot(date_list, \"Shape Files/Project_area.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78209a",
   "metadata": {},
   "source": [
    "## Confidence Level Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca38eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PP_ModisCL(PP_ModisFireCCI):\n",
    "    \"\"\"\n",
    "    Preprocessing class for the confidence level (%) that a burn has occurred in an area.\n",
    "    \n",
    "    Possible values (mask not image): \n",
    "        0 = pixel is not observed within month or is not burnable.\n",
    "        1-100 = expression of certainty in burn classification.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    filename_glob = \"*CL.tif\" \n",
    "    \n",
    "    \n",
    "    def plot(self, date_list, shape_root = None):   \n",
    "        \"\"\"Plots the data corresponding to each of the dates listed in date_list.\n",
    "\n",
    "        Args: \n",
    "            date_list: list of dates in the format \"YYYYMM\" that are requested for plotting\n",
    "            shape_root: shape file (.shp) path of training area (optional)\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: if object has not been populated with data before this function is called\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data is None:\n",
    "            raise ValueError(\"The data is = None. Try calling 'populate' to assign the object data before making this call.\") \n",
    "        \n",
    "        # Initialise the subplot object\n",
    "        plt.rcParams.update({'font.size': 13})\n",
    "        fig, ax = plt.subplots(len(date_list), figsize=(13,10*len(date_list)))\n",
    "        ticks = np.arange(0,101,10)\n",
    "        \n",
    "        # Prepare the colormap and force 0 -> black \n",
    "        cmap = plt.cm.plasma\n",
    "        cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "        cmaplist[0] = (0,0,0,1)\n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "        \n",
    "        for idx, date in enumerate(date_list):\n",
    "        \n",
    "            # Plot the data\n",
    "            self.data.sel(date=date).plot(ax=ax[idx], cmap=cmap, vmin=0, vmax=100, cbar_kwargs={'ticks': ticks,'label': 'Confidence (%)'});\n",
    "            ax[idx].set_title(date[4:] + '/' + date[:4], fontsize=20, fontweight=\"bold\");\n",
    "            ax[idx].set_xlabel('Longitude (\\N{DEGREE SIGN}W)',fontsize=16);\n",
    "            ax[idx].set_ylabel('Latitude (\\N{DEGREE SIGN}N)',fontsize=16);\n",
    "\n",
    "            # Optionally add a white square to illustrate the training area\n",
    "            if shape_root != None:\n",
    "                training_coords = extract_vertices(shape_root)\n",
    "                ax[idx].plot(training_coords[:,0],training_coords[:,1],'--w',linewidth=1.5);\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj = PP_ModisCL(\"Modis Data\")\n",
    "test_obj.populate()\n",
    "test_obj.crop(\"Shape Files/whole_map.shp\")\n",
    "date_list = [\"202003\",\"202004\",\"202005\"]\n",
    "test_obj.plot(date_list, \"Shape Files/Project_area.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b2cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
